# huibian_HM3

*学号：2015011340 姓名：骆轩源

#我的算法优化了：
1.倍增申请：向系统调用brk的操作数目为O(log(n))，其中n为最终堆占用的内存空间总长度。 由于n <= 内存总大小，假设内存为8G，那么调用次数不超过33。
2.合并：合并了相邻的空白块。
3.分裂操作：比如当前需要alloc 的大小为10,然后找到了一个大小为1024的空白块，按照原来的代码，这1024的空白块全部被它占用就很浪费，所以我的代码加入了
	  分裂优化，该空白块会被分裂成两个，一个10(不可用),一个1024-10-8 = 1006（可用）。

#将O(n)遍历优化到O(sqrt(n))：
在ppt给出的alloc的代码中，需要从第一个块到最后一个块遍历来查找合适的空白块，复杂度时O(n)，其中n为块的个数，由于最坏情况，块的个数和堆所能开的大小近似相等
(当块的大小都为1的时候)，我们不妨设n为能用到的内存数。

我们令`k = sqrt(n)`，然后我们将`空白内存块`按照其size = 1,2,3,..,k和>k分类。 可以知道一共被分成了k + 1类。
其中size > k的`空白内存块`的个数`不超过sqrt(n)`，不然就会得到n > sqrt(n) * k = n。 接下来我们要对每一类构造一个链表，一共`k + 1个链表`。

对于任意1 <= i <= k，我们把所有size = i的`空白块`用链表连接起来（顺序无关，也就是`不需要`按照其在内存上的左右顺序存储），
然后对于size > k的`空白块`，我们也把他们按照任意顺序用链表连接起来。

这样遇到一个大小为t的alloc请求时，我们先去查看 size = t,size = t + 1,size = t + 2,...,size = k 这些O(sqrt(n))个链表的表头是否为空，只要有一个不为空，就从该链表的尾巴随便拿走一个空白块即可，如果找不到，则在size > k的那个链表中遍历该链表所有元素（不超过O(sqrt(n))个），找到一个比t大的拿出来
，这样alloc的复杂度是O(sqrt(n)) + O(1)。

dealloc时，如果产生新的空白块就按照其大小，插入到对应链表的尾巴，复杂度为O(1)。

综上我们只需要记录k + 1个表头，即可`在O(sqrt(n))的时间内做到alloc和dealloc`。

PS: 但是由于时间不足，没能在DDL之前调试出来。所以只能把想法放出来了。

#具体的实现方法：
1.优化系统调用的方法是，记录最近一次向系统申请增加的堆的长度的大小，记为current_size，假设遇到了一个新的allocate请求空间为asked_size,并且
  当前没有空白块可以放下，那么就将堆的长度扩大max(current_size * 2,asked_size)，可以证明，第i次申请的大小至少为2^i。故证明了系统调用次数为
  O(log n)级别。 

2.空白区域的合并，是每一次释放操作时，从头到尾扫描合并。

#实验准备：
1.实验代码：alloc.s, newalloc.s, alloc_with_clear.s
	其中alloc.s是ppt上的代码，每一次扩展是直接扩展所需空间，也不做合并相邻空白块的优化。
	   newalloc.s是加上了按2的幂扩展的优化，减少了系统调用，实现了分裂操作。
	   alloc_with_clear.s是同时加上了空白块合并优化，以及2的幂优化，实现了分裂操作。
	   
2.测试代码：mkdata.py,test.s

其中mkdata.py用来生成测试代码，测试代码中，首先输出当前break位置，然后运行n条指令，n条指令为随机生成的alloc和dealloc指令，为了在dealloc操作时
知道需要释放的位置，需要用一个很大的栈记录每一次alloc后返回的eax，我是按照对应编号存的，第i个alloc指令的返回结果，被存到了栈的4*i(%ebp)。

设置好mkdata.py，运行`python mkdata.py`，就会生成test.s，这时只需要分别运行：

*`bash run.sh`  //该指令测试alloc.s中实现的代码
*`bash run2.sh` //该指令测试alloc_with_clear.s中实现的代码
*`bash run3.sh` //该指令测试newalloc.s中实现的代码

#实验1（系统调用优化）：

本实验中，mkdata.py只生成500000条 alloc指令，返回地址也不存储到栈（随便存到了4(%ebp)），参与对比的代码是alloc.s和newalloc.s

快速的使用方法为，将test1.s重命名为test.s之后，执行run.sh和run3.sh即可

对于alloc.s的返回结果为(run.sh)：
	root@f42aaf989e67:/home/huibian_HM3# time ./test
	brk(0):149942272
	brk(0):154442272

	real	5m1.727s
	user	5m1.556s
	sys	0m0.188s

对于newalloc.s的返回结果为(run3.sh)：
	root@f42aaf989e67:/home/huibian_HM3# time ./test3
	brk(0):155914240
	brk(0):164303031

	real	5m1.824s
	user	5m1.820s
	sys	0m0.016s

可以看到减少系统调用之后，时间并没有减少，我认为原因是，原本的代码中，没有考虑分裂操作，而我的新代码中有分裂操作，分裂操作的常数和系统调用持平，故
没有多大影响。

#实验2（合并空白优化：）

本实验中，mkdata.py中生成100条alloc和dealloc指令，其中生成alloc指令的概率为20%，每次申请的大小是取自[1,200]的随机数，dealloc是随机从当前
还没有没释放的块中选择一块。

快速的使用方法为，将test2.s重命名为test.s之后，执行run2.sh和run3.sh即可

对于alloc_with_free.s的返回结果为(run2.sh):
	root@f42aaf989e67:/home/huibian_HM3# ./test2
	brk(0):152702976
	brk(0):152703728

得到一共扩展的堆空间为：152703728 - 152702976 = 752

对于newalloc.s的返回结果为(run3.sh):
	root@f42aaf989e67:/home/huibian_HM3# ./test3
	brk(0):136527872
	brk(0):136529464
得到一共扩展的堆空间为：136529464 - 136527872 = 1592

本实验中设置alloc指令的概率远比dealloc小是为了尽量产生位置相邻的空块，让效果更加明显，从结果来看，优化效果显著。

#一些思考：

  对于第2个优化系统调用次数，我认为page_size并没有什么理论保证，故实现的是按照递增的2的幂来申请空间，这样的系统调用时间减少了，但是仅仅看系统调用次数
  是没有意义的，考虑一次性调用全部的空间，这样系统调用就只有一次，但是浪费了很多空间。
  
  按照2的幂，可以保证浪费的空间不超过O(n)，其中n为最终内存空间中最后一个被利用(曾经有，但是被释放掉也算被利用过)的位置。这是因为，假设最后一次申请空间是第k次，那么有：
  2^(k - 1) <= n <= 2^k，所以浪费的空间 <= 2^k - 2^(k - 1) = 2^(k - 1)。
  
  还可以每一次申请不翻倍，只加1，那么就有至多O(sqrt(n))次系统调用，浪费的空间最多为O(sqrt(n))，这是因为，假设最后一次调用申请的空间是第k次，那么有：
  k(k + 1) /2 <= n <= (k + 1)(k + 2)/2 ，浪费的空间 <= (k + 1)(k + 2)/ 2 - k(k + 1) / 2 = k + 1。 而k = O(sqrt(n))。
  
  所以可以看到，当希望时间少的时候，空间就会多，二者很难兼得，sqrt(n)就是一个很好的平衡。
  

